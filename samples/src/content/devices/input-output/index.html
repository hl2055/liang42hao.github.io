<!DOCTYPE html>
<!--
 *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree.
-->
<html>
<head>

  <meta charset="utf-8">
  <meta name="description" content="WebRTC code samples">
  <meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1">
  <meta itemprop="description" content="Client-side WebRTC code samples">
  <meta itemprop="image" content="../../../images/webrtc-icon-192x192.png">
  <meta itemprop="name" content="WebRTC code samples">
  <meta name="mobile-web-app-capable" content="yes">
  <meta id="theme-color" name="theme-color" content="#ffffff">

  <base target="_blank">

  <title>Select audio and video sources</title>

  <link rel="icon" sizes="192x192" href="../../../images/webrtc-icon-192x192.png">
  <link href="//fonts.googleapis.com/css?family=Roboto:300,400,500,700" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="../../../css/main.css">

  <style>
    div.select {
      display: inline-block;
      margin: 0 0 1em 0;
    }
    p.small {
      font-size: 0.7em;
    }
    label {
      width: 12em;
      display: inline-block;
    }
  </style>

</head>

<body>
  <div id="container">

    <div class="highlight">
      <p>New codelab: <a href="https://codelabs.developers.google.com/codelabs/webrtc-web">Realtime communication with WebRTC</a></p>
    </div>

    <h1><a href="//webrtc.github.io/samples/" title="WebRTC samples homepage">WebRTC samples</a><span>Select sources &amp; outputs</span></h1>

    <p>Get available audio, video sources and audio output devices from <code>mediaDevices.enumerateDevices()</code> then set the source for <code>getUserMedia()</code> using a <code>deviceId</code> constraint.</p>

    <div class="select">
      <label for="audioSource">Audio input source: </label><select id="audioSource"></select>
    </div>

    <div class="select">
      <label for="audioOutput">Audio output destination: </label><select id="audioOutput"></select>
    </div>

    <div class="select">
      <label for="videoSource">Video source: </label><select id="videoSource"></select>
    </div>

    <video id="video" autoplay></video>
    <div id="results">
      <span id="final_span" class="final"></span>
      <span id="interim_span" class="interim"></span>
    </div>

    <p class="small"><b>Note:</b> If you hear a reverb sound your microphone is picking up the output of your speakers/headset, lower the volume and/or move the microphone further away from your speakers/headset.</p>

    <a href="https://github.com/webrtc/samples/tree/gh-pages/src/content/devices/input-output" title="View source for this page on GitHub" id="viewSource">View source on GitHub</a>
  </div>

  <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
  <script src="../../../js/common.js"></script>
  <script src="js/main.js"></script>

  <script src="../../../js/lib/ga.js"></script>
  <script>
  function speech2text() {
   var final_transcript = '';
   var recognizing = false;

   if ('webkitSpeechRecognition' in window) {

      var recognition = new webkitSpeechRecognition();

      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onstart = function() {
         recognizing = true;
      };

      recognition.onerror = function(event) {
         console.log(event.error);
      };

      recognition.onend = function() {
         recognizing = false;
         speech2text();
      };

      recognition.onresult = function(event) {
         var interim_transcript = '';
         for (var i = event.resultIndex; i < event.results.length; ++i) {
            if (event.results[i].isFinal) {
               final_transcript += event.results[i][0].transcript;
            } else {
               interim_transcript += event.results[i][0].transcript;
            }
         }
         final_transcript = capitalize(final_transcript);
         final_span.innerHTML = linebreak(final_transcript);
         interim_span.innerHTML = linebreak(interim_transcript);

      };
   }

   var two_line = /\n\n/g;
   var one_line = /\n/g;

   function linebreak(s) {
      return s.replace(two_line, '<p></p>').replace(one_line, '<br>');
   }

   function capitalize(s) {
      return s.replace(s.substr(0, 1), function(m) {
         return m.toUpperCase();
      });
   }

   function startDictation(event) {
      if (recognizing) {
         recognition.stop();
         return;
      }
      final_transcript = '';
      recognition.lang = 'en-US';
      recognition.start();
      final_span.innerHTML = '';
      interim_span.innerHTML = '';
   }

   startDictation(event);

}

speech2text();
  </script>
</body>
</html>
